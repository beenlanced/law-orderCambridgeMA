---
title: "Law&Order Cambridge Tuesday Tutorial"
author: "Lance Hester"
date: "4/16/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#Data Science Case Study: Cambridge Crimes!

Data Scientists take a bite out of crime! That's right! 

In the following code, we are going to explore Cambridge, MA crime data made available here:

* https://data.cambridgema.gov/Public-Safety/Crime-Reports/xuad-73uj


```{r}
# Let's load a bunch of libraries that will be helpful
library(cluster)
library(dplyr)
library(factoextra)
library(ggfortify)
library(ggmap)
library(ggplot2)
library(ggthemes)
library(maps)
library(tidyr)
library(viridis)
```

# Get Data
```{r}
cambridge <-read.table('Crime_Reports.csv', header=TRUE, sep = ',')
#summary(cambridge)

#nrow --- How many observations do we have?
nrow(cambridge)

#ncol--- How many features/columns do we have? 
ncol(cambridge)

#Get Column Names
colnames(cambridge)

```


## Breakdown of our Data

* *File Number* - Report number of the crime report

* *Date.of.Report* - Date crime report was reported 

* *Date* - Date and Time of the crime (12/18/2018 hh:mm  - 12/20/2018 hh:mm) can be single date or range

* *Crime* - Type of crime (over 40 different types)

* *Area* - Reporting Area - (e.g., 607) police area. I think it is refers to zone for specific police units

* *Neighborhood* - Section of Cambridge where crime occurred (e.g., Mid-Cambridge)

* *Location* - Cambridge address (e.g., 200 Broadway, Cambridge)



```{r}
head(cambridge,10)
```


### Yikes! Looks Like We Need to Clean the Data
Look at the **Crime.Date.Time** fields and the **Date.of.Report** columns, their formats are a bit different

Plus, let's make sure we do not have duplicate crime reports.

Also, we will want to make sure there are no missing values anywhere for analysis.

And, let's create four new columns.

* occurenceyear
* occurrencemonth
* occurrencehour
* occurenceday

```{r}
#first drop all rows with missing values
cambridge <- cambridge[complete.cases(cambridge), ]

#now let us create new occurenceyear column by doing some string manipulation
cambridge <- cambridge %>%
  mutate(occurrenceyear = substr(as.character(File.Number), 1,4))

# create occurence month (1-12) 
cambridge <- cambridge %>%
  mutate(occurrencemonth = month.abb[as.numeric(substr(as.character(Crime.Date.Time), 1,2))])

cambridge <- cambridge %>%
  mutate(occurrencehour = as.numeric(substr(as.character(Crime.Date.Time), 12,13)))

cambridge <- cambridge %>%
  mutate(occurrenceday = weekdays(as.Date(substr(as.character(Crime.Date.Time), 1,10),"%m/%d/%Y")))

```


## Let's See How Many Unique Years We Have

```{r}
unique(cambridge$occurrenceyear)
```

## Let's See How Many Crime Reports Per Year

```{r}
year_group <- group_by(cambridge, occurrenceyear)
crime_by_year <- summarise(year_group, n=n())
crime_by_year
```


##Lots of Occurences per Year, We Will Focus on 2018 for Most of Our Analysis

```{r}
cambridge2018 <- cambridge[cambridge$occurrenceyear =="2018", ]
#just in case let's make sure we do not have any missing values
cambridge2018 <- cambridge2018[complete.cases(cambridge2018), ]
```


## What Were the Major Crimes in 2018


```{r}
indicator_group <- group_by(cambridge2018, Crime)
crime_by_indicator <- summarise(indicator_group, n=n())
crime_by_indicator <- crime_by_indicator[order(crime_by_indicator$n, decreasing = TRUE),]
#crime_by_indicator;
```

```{r}
ggplot(aes(x = reorder(Crime, n), y = n), data = crime_by_indicator) +
  geom_bar(stat = 'identity', width = 0.5) +
  geom_text(aes(label = n), stat = 'identity', data = crime_by_indicator, hjust = -0.1, size = 3.5) +
  coord_flip() +
  xlab('Major Crime Indicators') +
  ylab('Number of Occurrences') +
  ggtitle('Major Crime Indicators Cambridge 2018') +
  theme_bw() +
  theme(plot.title = element_text(size = 16),
        axis.title = element_text(size = 12, face = "bold"))
```

**Looks like you have to be careful parking in Cambridge!**


## Okay, Okay, But When Do the Crimes Go Down During the Day?


```{r}
hour_group <- group_by(cambridge2018, occurrencehour)
crime_hour <- summarise(hour_group, n=n())
ggplot(aes(x=occurrencehour, y=n), data = crime_hour) + geom_line(size = 2.5, alpha = 0.7, color = "mediumseagreen", group=1) + 
  geom_point(size = 0.5) + 
  ggtitle('Total Crimes by Hour of Day in Cambridge 2018') +
  ylab('Number of Occurrences') +
  xlab('Hour(24-hour clock)') +
  theme_bw() +
  theme(plot.title = element_text(size = 16),
        axis.title = element_text(size = 12, face = "bold"))
```


#### Wow! Looks like lunch time (Noon) is the high crime time, but dips after 7 PM

**Why?**

Looking back at the total crimes the top Crimes include:

* **Hit and Run (641)** -- Lots of cars and traffic on the road at lunch time
* Domestic Assault (471) -- Low blood sugar, hangries(?)
* Simple Assault (423) -- Low blood sugar, hangries(?)
* Shoplifting (338) -- primetime shopping
* **Larceny by Bicycle (306)** -- Lots of bicycle locking up during that time of day.


7 pm: People leave Cambridge area after work and Campus life starts to cool off as we hit the evening. 


##  Let's Dig Deeper --- More Crimes by the Times


```{r}
#hour_crime_group <- group_by(cambridge2018, occurrencehour, Crime)
top5_crime <- cambridge2018 %>% 
                filter(Crime %in% c("Hit and Run", "Domestic Dispute", "Simple Assault", "Shoplifting","Larceny of Bicycle")) %>% 
                select(occurrencehour,Crime)
hour_crime_group <- group_by(top5_crime, occurrencehour, Crime) 
hour_crime <- summarise(hour_crime_group, n=n())
ggplot(aes(x=occurrencehour, y=n, color=Crime), data = hour_crime) + 
  geom_line(size=1.5) + 
  ggtitle('Top 5 Crime Types by Hour of Day in Cambridge 2018') +
  ylab('Number of Occurrences') +
  xlab('Hour(24-hour clock)') +
  theme_bw() +
  theme(plot.title = element_text(size = 16),
        axis.title = element_text(size = 12, face = "bold"))
```


# Top 5 Crimes by Hour of Day Analysis
* **Hit and Runs** act like its there job! They follow Normal Business day Hours ramping-up in the morning and cooling off in post rush hours. Check out the pick up around lunch hours.

* **Shoplifting** tracks with store openings and closings

* **Simple Assaults** happen in the wee hours of the night and pick-up during the day. 

* **Domestice Disputes** has a curious spike around 1 am, drops off, and picks up during the day. People Need there sleep I guess to fight later. Highest after 8 pm

* Don't park your bike in Cambridge around 8-9 am or 5-6 pm.


#Where Are These Crimes Happening?


```{r}
location_group <- group_by(cambridge2018, Neighborhood)
crime_by_location <- summarise(location_group, n=n())
crime_by_location <- crime_by_location[order(crime_by_location$n, decreasing = TRUE), ]
crime_by_location_top20 <- head(crime_by_location, 20)
#crime_by_location_top20
```

```{r}
ggplot(aes(x = reorder(Neighborhood, n), y = n), data = crime_by_location_top20) +
  geom_bar(stat = 'identity', width = 0.6) +
  geom_text(aes(label = n), stat = 'identity', data = crime_by_location_top20, hjust = -0.1, size = 3) +
  coord_flip() +
  xlab('Neighborhoods') +
  ylab('Number of Occurrences') +
  ggtitle('Neighborhoods with Most Crimes - Top 20') +
  theme_bw() +
  theme(plot.title = element_text(size = 16),
        axis.title = element_text(size = 12, face = "bold"))
```


##### FYI: Area 4 is the Port (according to Dr. Google)
Bounded by Hampshire Street to the north, the Boston & Albany Railroad to the east, Prospect Street to the west, and Massachusetts Avenue to the south.
Most of The Port is residential in character. However, the triangle in the southern part of the neighborhood bounded by Massachusetts Avenue, Main Street, and the Grand Junction Railroad (sometimes known as the Osborn Triangle) is a former industrial center now home to high-tech labs and offices, as well as facilities for the neighboring Massachusetts Institute of Technology.


### The Most Dangerous Neighborhood in 2018 was Cambridgeport, but East Cambridge Was Not Far Behind. 


#### Cambridgeport (according to Dr. Google)
Area 5 of Cambridge

"SOMA" or "South of Massachusetts Avenue". It is bounded by Massachusetts Avenue, the Charles Reiver and the Grand Junction Railroad, and River street. The neighborhood contains predominantly residential homes, lots of triple deckers.

Central Square, at the northernmost part of Cambridgeport is an active commercial district and transportation hub. **[Lots of vehicle and human traffic!]**

I gather it is working-class area as the average household income is $45,294.00


#### East Cambridge (According to Dr. Google)
Area 1 of Cambridge

East Cambridge is bounded by the Charles River and the Charlestown neighborhood of Boston on the east, the Somerville border on the north, Broadway and Main Street on the south, and the railroad tracks on the west.

There are predominantly Irish and Portuguese natives, with a mix of Polish and Italians along with professionals who work in Boston and Kendall Square. It is predominantly a **middle-class neighborhood**

Average household income was $47,979.00

### The Safest Neighborhood in 2018 was Strawberry Hill! 


```{r}
tail(crime_by_location,6)
```


#### Strawberry Hill (according to Dr. Google)
Area 13

Smallest neighborhood by land in Cambridge. Contains the Fresh Pond Reservation and part of the Thomas P. Oâ€™Neill, Jr. Municipal Golf Course. 

It is bounded by the town of Belmont on the west, Watertown on the south, Aberdeen Avenue on the east, and Fresh Pond on the north.

Higher income area:

Average household income was $74,107. The altitude is around 114 feet above sea level making it the highest natural altitude in Cambridge.


# How Do Neighborhoods Compare According to Crimes?


```{r}
offence_location_group <- group_by(cambridge2018, Neighborhood, Crime)
offence_type_by_location <- summarise(offence_location_group, n=n())
offence_type_by_location <- offence_type_by_location[order(offence_type_by_location$n, decreasing = TRUE), ]
offence_type_by_location_top20 <- head(offence_type_by_location, 20)
ggplot(aes(x = Neighborhood, y=n, fill = Crime), data=offence_type_by_location_top20) +
  geom_bar(stat = 'identity', position = position_dodge(), width = 0.8) +
  xlab('Neighborhood') +
  ylab('Number of Occurrences') +
  ggtitle('Top Crimes vs. Neighborhood Cambridge 2018') + theme_bw() +
  theme(plot.title = element_text(size = 16),
        axis.title = element_text(size = 12, face = "bold"),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = .4))
```


Overall, we see hit and runs touch every neighborhood-- Car insurance must be high!

Don't own a store in East Cambridge cause, well, shoplifting is "for Realz"" there.

Don't park your car in North Cambridge most car break-ins/stolen cars (Larceny Motor Vehicle)

Don't buy a home in Riverside, most building thefts (Larceny from Building)


# Does The Time of the Year Matter?

```{r}
crime_count <- cambridge2018 %>% group_by(occurrencemonth, Crime) %>% summarise(Total = n())
crime_count$occurrencemonth <- ordered(crime_count$occurrencemonth, levels = c('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep','Oct','Nov', 'Dec'))
ggplot(crime_count, aes(occurrencemonth, Crime, fill = Total)) +
  geom_tile(size = 1, color = "white") +
  scale_fill_viridis()  +
  geom_text(aes(label=Total), color='white') +
  ggtitle("Crime Indicators by Month 2018") +
  xlab('Month') +
  theme(plot.title = element_text(size = 16), 
        axis.title = element_text(size = 12, face = "bold"))
```


"Hit and Runs"" (Yellow/Green Squares) are the most common type of crime all year around, every month. **January** looks to be the worst month. Maybe more hits because of the weather, the holiday season celebrations, and playoff football.  Go Pats! 

Larceny of Bicycles (Bike Thefts) spike in **August**-- probably due to start of school years.

Domestic Disputes also stay high each month of the year.


# How About Crimes per Day of the Week?

```{r}
day_count <- cambridge2018 %>% group_by(occurrenceday, Crime) %>% summarise(Total = n())
ggplot(day_count, aes(occurrenceday, Crime, fill = Total)) +
  geom_tile(size = 1, color = "white") +
  scale_fill_viridis()  +
  geom_text(aes(label=Total), color='white') +
  ggtitle("Crime Indicators by Day of Week 2018") +
  xlab('Day of Week') +
  theme(plot.title = element_text(size = 16), 
        axis.title = element_text(size = 12, face = "bold"))
```

Fridays and Wednesdays see the largest number of *Hit and Runs*. 

*Domestic Disputes* were nearly consistent every day of the week.



##K-Means Clustering -  Let's see how Machines Interpret Our Data

```{r}
#Make long data format wide data format
by_groups <- group_by(cambridge2018, Crime, Neighborhood)
groups <- summarise(by_groups, n=n())
groups <- groups[c("Neighborhood", "Crime", "n")]
groups_wide <- spread(groups, key = Crime, value = n)
#groups_wide
```

```{r}
# clean up data for clustering analysis

# Remove the neighborhood column for analysis
kdata <- groups_wide[,-c(1,1)]

# We have a bunch of NA values in the data so let's replace them with zeros 
kdata[is.na(kdata)] <- 0

#Normally we would standardize data, but the magnitudes are not an issue here
# data needs to be scaled (i.e., standardized [0,1]) to make computations easier
#kdata_mean <- apply(kdata, 2, mean)
#kdata_std  <- apply(kdata, 2, sd)
#kdata <- scale(kdata, kdata_mean, kdata_std)
```

##How Many Clusters?

```{r}
# Determine the number of clusters looking at Elbow Curve 
# use withinss - the within cluster sum of squares- want lowest value as possible
#     ss is sum of squares - metric kmeans uses to know how compact a cluster and how different clusters
#                      are several clusters among themselves. 
wss <- (nrow(kdata)-1) * sum(apply(kdata, 2, var))
for (i in 2:12) wss[i] <- sum(kmeans(kdata, centers=i)$withiness)
plot(1:12, wss, type='b', xlab='Number of Clusters', ylab='Within groups sum of squares')
```

### Elbow plots show significant elbow at 2.

Based on the plot, we can say with confidence that we do not need more than two clusters (two) centroids

# Fitting our Kmeans Learning Model to 2 Clusters

```{r}
kcluster <- kmeans(kdata, 2)
kcluster
```

### Interpreting the Cluster Results:
From our 13 neighborhoods

* We have two clusters 
      * Cluster 1 has 7 neighborhoods
      * Cluster 2 has 6 neighborhoods

* Cluster Means:
      * Cluster 1 : means higher than most crime types
      * Cluster 2 : means lower than most crime types
      * Note: It is good that the two groups have significant variances in every variable, as it indicates each variable (crime type) plays a signficant role in categorizing the clusters.
      
* Clustering Vector:
First neighborhood belongs to Cluster 2, (second,third,fourth) neighborhood belong to Cluster 1, and so on.

* Within Cluster Sum of Squares by Cluster

      *Withinss tells us the sum of the square of the distance from each data point to the cluster center. Lower is better. I did not standardize values so the number looks high.
      
      *Betweenss tells us the sum of the squared distance between cluster centers.  Ideally we want cluster centers far apart from each other.


#Plotting the K-means Results

```{r}

#z1 <- data.frame(kdata, kcluster$cluster)
#result.pca <-prcomp(z1)
fviz_cluster(kcluster, kdata)
#autoplot(result.pca, data=kdata, color=kcluster$cluster)


#plot(kdata, col=kcluster$clusterk)
```

```{r}

#groups_wide$Neighborhood
#kcluster$cluster
x_df <- data.frame("neighborhood" = groups_wide$Neighborhood, "cluster" = kcluster$cluster)


head(x_df ,13)
```